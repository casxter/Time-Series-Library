seq_len: 720, label_len: 360, pred_len: 360
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           20240702-214104     Model:              Transformer         

[1mData Loader[0m
  Data:               custom              Root Path:          /home/qc/twj/ml_data/data2/
  Data Path:          #0_hour_residual_ae.csvFeatures:           MS                  
  Target:             residual_ae         Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            720                 Label Len:          360                 
  Pred Len:           360                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             4                   Dec In:             4                   
  C Out:              4                   d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                soh-residual_ae-#0  Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_20240702-214104_Transformer_custom_ftMS_sl720_ll360_pl360_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_soh-residual_ae-#0_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 9152
val 1104
test 2564
======================================================================
Layer (type:depth-idx)                        Param #
======================================================================
Model                                         --
â”œâ”€DataEmbedding: 1-1                          --
â”‚    â””â”€TokenEmbedding: 2-1                    --
â”‚    â”‚    â””â”€Conv1d: 3-1                       6,144
â”‚    â””â”€PositionalEmbedding: 2-2               --
â”‚    â””â”€TimeFeatureEmbedding: 2-3              --
â”‚    â”‚    â””â”€Linear: 3-2                       2,048
â”‚    â””â”€Dropout: 2-4                           --
â”œâ”€Encoder: 1-2                                --
â”‚    â””â”€ModuleList: 2-5                        --
â”‚    â”‚    â””â”€EncoderLayer: 3-3                 3,152,384
â”‚    â”‚    â””â”€EncoderLayer: 3-4                 3,152,384
â”‚    â””â”€LayerNorm: 2-6                         1,024
â”œâ”€DataEmbedding: 1-3                          --
â”‚    â””â”€TokenEmbedding: 2-7                    --
â”‚    â”‚    â””â”€Conv1d: 3-5                       6,144
â”‚    â””â”€PositionalEmbedding: 2-8               --
â”‚    â””â”€TimeFeatureEmbedding: 2-9              --
â”‚    â”‚    â””â”€Linear: 3-6                       2,048
â”‚    â””â”€Dropout: 2-10                          --
â”œâ”€Decoder: 1-4                                --
â”‚    â””â”€ModuleList: 2-11                       --
â”‚    â”‚    â””â”€DecoderLayer: 3-7                 4,204,032
â”‚    â””â”€LayerNorm: 2-12                        1,024
â”‚    â””â”€Linear: 2-13                           2,052
======================================================================
Total params: 10,529,284
Trainable params: 10,529,284
Non-trainable params: 0
======================================================================
	iters: 57, epoch: 1 | loss: 0.0366051
	speed: 0.2271s/iter; left time: 636.7859s
	iters: 114, epoch: 1 | loss: 0.0164553
	speed: 0.2065s/iter; left time: 567.3374s
	iters: 171, epoch: 1 | loss: 0.0146021
	speed: 0.2067s/iter; left time: 555.9552s
	iters: 228, epoch: 1 | loss: 0.0098757
	speed: 0.2071s/iter; left time: 545.1651s
	iters: 285, epoch: 1 | loss: 0.0084482
	speed: 0.2074s/iter; left time: 534.2013s
Epoch: 1 cost time: 60.351715326309204
Epoch: 1, Steps: 286 | Train Loss: 0.0504430 Vali Loss: 0.0286034 Test Loss: 0.1682117
Validation loss decreased (inf --> 0.028603).  Saving model ...
Updating learning rate to 0.0001
	iters: 57, epoch: 2 | loss: 0.0099107
	speed: 0.3542s/iter; left time: 891.8552s
	iters: 114, epoch: 2 | loss: 0.0058541
	speed: 0.2076s/iter; left time: 510.9916s
	iters: 171, epoch: 2 | loss: 0.0054483
	speed: 0.2076s/iter; left time: 499.1144s
	iters: 228, epoch: 2 | loss: 0.0052531
	speed: 0.2077s/iter; left time: 487.5113s
	iters: 285, epoch: 2 | loss: 0.0061608
	speed: 0.2078s/iter; left time: 475.8691s
Epoch: 2 cost time: 59.53813338279724
Epoch: 2, Steps: 286 | Train Loss: 0.0066198 Vali Loss: 0.0858837 Test Loss: 0.3661725
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 57, epoch: 3 | loss: 0.0044355
	speed: 0.3542s/iter; left time: 790.5820s
	iters: 114, epoch: 3 | loss: 0.0038841
	speed: 0.2078s/iter; left time: 452.0603s
	iters: 171, epoch: 3 | loss: 0.0040458
	speed: 0.2079s/iter; left time: 440.3936s
	iters: 228, epoch: 3 | loss: 0.0036868
	speed: 0.2080s/iter; left time: 428.5878s
	iters: 285, epoch: 3 | loss: 0.0035017
	speed: 0.2079s/iter; left time: 416.6523s
Epoch: 3 cost time: 59.58953309059143
Epoch: 3, Steps: 286 | Train Loss: 0.0042717 Vali Loss: 0.1627351 Test Loss: 0.4973442
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
	iters: 57, epoch: 4 | loss: 0.0038372
	speed: 0.3556s/iter; left time: 691.9979s
	iters: 114, epoch: 4 | loss: 0.0032957
	speed: 0.2079s/iter; left time: 392.7768s
	iters: 171, epoch: 4 | loss: 0.0034132
	speed: 0.2079s/iter; left time: 380.8615s
	iters: 228, epoch: 4 | loss: 0.0034789
	speed: 0.2078s/iter; left time: 368.8777s
	iters: 285, epoch: 4 | loss: 0.0037450
	speed: 0.2079s/iter; left time: 357.1664s
Epoch: 4 cost time: 59.60947823524475
Epoch: 4, Steps: 286 | Train Loss: 0.0035588 Vali Loss: 0.1591842 Test Loss: 0.4996560
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_20240702-214104_Transformer_custom_ftMS_sl720_ll360_pl360_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_soh-residual_ae-#0_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2564
test shape: (80, 32, 360, 1) (80, 32, 360, 1)
test shape: (2560, 360, 1) (2560, 360, 1)
mae:0.3670364022254944 mse:0.16821162402629852 rmse:0.4101361036300659 mape:0.5045068264007568 mspe:61.71311950683594 dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           20240702-214544     Model:              Informer            

[1mData Loader[0m
  Data:               custom              Root Path:          /home/qc/twj/ml_data/data2/
  Data Path:          #0_hour_residual_ae.csvFeatures:           MS                  
  Target:             residual_ae         Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            720                 Label Len:          360                 
  Pred Len:           360                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             4                   Dec In:             4                   
  C Out:              4                   d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                soh-residual_ae-#0  Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_20240702-214544_Informer_custom_ftMS_sl720_ll360_pl360_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_soh-residual_ae-#0_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 9152
val 1104
test 2564
======================================================================
Layer (type:depth-idx)                        Param #
======================================================================
Model                                         --
â”œâ”€DataEmbedding: 1-1                          --
â”‚    â””â”€TokenEmbedding: 2-1                    --
â”‚    â”‚    â””â”€Conv1d: 3-1                       6,144
â”‚    â””â”€PositionalEmbedding: 2-2               --
â”‚    â””â”€TimeFeatureEmbedding: 2-3              --
â”‚    â”‚    â””â”€Linear: 3-2                       2,048
â”‚    â””â”€Dropout: 2-4                           --
â”œâ”€DataEmbedding: 1-2                          --
â”‚    â””â”€TokenEmbedding: 2-5                    --
â”‚    â”‚    â””â”€Conv1d: 3-3                       6,144
â”‚    â””â”€PositionalEmbedding: 2-6               --
â”‚    â””â”€TimeFeatureEmbedding: 2-7              --
â”‚    â”‚    â””â”€Linear: 3-4                       2,048
â”‚    â””â”€Dropout: 2-8                           --
â”œâ”€Encoder: 1-3                                --
â”‚    â””â”€ModuleList: 2-9                        --
â”‚    â”‚    â””â”€EncoderLayer: 3-5                 3,152,384
â”‚    â”‚    â””â”€EncoderLayer: 3-6                 3,152,384
â”‚    â””â”€ModuleList: 2-10                       --
â”‚    â”‚    â””â”€ConvLayer: 3-7                    787,968
â”‚    â””â”€LayerNorm: 2-11                        1,024
â”œâ”€Decoder: 1-4                                --
â”‚    â””â”€ModuleList: 2-12                       --
â”‚    â”‚    â””â”€DecoderLayer: 3-8                 4,204,032
â”‚    â””â”€LayerNorm: 2-13                        1,024
â”‚    â””â”€Linear: 2-14                           2,052
======================================================================
Total params: 11,317,252
Trainable params: 11,317,252
Non-trainable params: 0
======================================================================
	iters: 57, epoch: 1 | loss: 0.0430241
	speed: 0.1511s/iter; left time: 423.8102s
	iters: 114, epoch: 1 | loss: 0.0220481
	speed: 0.1257s/iter; left time: 345.2512s
	iters: 171, epoch: 1 | loss: 0.0225526
	speed: 0.1257s/iter; left time: 338.1167s
	iters: 228, epoch: 1 | loss: 0.0115263
	speed: 0.1257s/iter; left time: 330.8700s
	iters: 285, epoch: 1 | loss: 0.0134195
	speed: 0.1257s/iter; left time: 323.7549s
Epoch: 1 cost time: 37.48116087913513
Epoch: 1, Steps: 286 | Train Loss: 0.0458947 Vali Loss: 0.0606207 Test Loss: 0.6327684
Validation loss decreased (inf --> 0.060621).  Saving model ...
Updating learning rate to 0.0001
	iters: 57, epoch: 2 | loss: 0.0083520
	speed: 0.2451s/iter; left time: 617.2832s
	iters: 114, epoch: 2 | loss: 0.0108296
	speed: 0.1256s/iter; left time: 309.1455s
	iters: 171, epoch: 2 | loss: 0.0125097
	speed: 0.1256s/iter; left time: 302.0505s
	iters: 228, epoch: 2 | loss: 0.0129203
	speed: 0.1256s/iter; left time: 294.8941s
	iters: 285, epoch: 2 | loss: 0.0075233
	speed: 0.1256s/iter; left time: 287.7346s
Epoch: 2 cost time: 36.21613645553589
Epoch: 2, Steps: 286 | Train Loss: 0.0103035 Vali Loss: 0.0964258 Test Loss: 0.8306826
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 57, epoch: 3 | loss: 0.0056680
	speed: 0.2442s/iter; left time: 544.9557s
	iters: 114, epoch: 3 | loss: 0.0065425
	speed: 0.1257s/iter; left time: 273.3341s
	iters: 171, epoch: 3 | loss: 0.0055349
	speed: 0.1257s/iter; left time: 266.1950s
	iters: 228, epoch: 3 | loss: 0.0060026
	speed: 0.1257s/iter; left time: 259.0168s
	iters: 285, epoch: 3 | loss: 0.0063783
	speed: 0.1257s/iter; left time: 251.8063s
Epoch: 3 cost time: 36.21706509590149
Epoch: 3, Steps: 286 | Train Loss: 0.0069684 Vali Loss: 0.0884148 Test Loss: 0.8582217
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
	iters: 57, epoch: 4 | loss: 0.0051732
	speed: 0.2457s/iter; left time: 478.1517s
	iters: 114, epoch: 4 | loss: 0.0051908
	speed: 0.1257s/iter; left time: 237.3946s
	iters: 171, epoch: 4 | loss: 0.0036792
	speed: 0.1257s/iter; left time: 230.2253s
	iters: 228, epoch: 4 | loss: 0.0058437
	speed: 0.1257s/iter; left time: 223.0680s
	iters: 285, epoch: 4 | loss: 0.0049599
	speed: 0.1257s/iter; left time: 215.9117s
Epoch: 4 cost time: 36.23064994812012
Epoch: 4, Steps: 286 | Train Loss: 0.0055563 Vali Loss: 0.1448387 Test Loss: 1.0583627
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_20240702-214544_Informer_custom_ftMS_sl720_ll360_pl360_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_soh-residual_ae-#0_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2564
test shape: (80, 32, 360, 1) (80, 32, 360, 1)
test shape: (2560, 360, 1) (2560, 360, 1)
mae:0.7284896373748779 mse:0.6326609253883362 rmse:0.7953998446464539 mape:0.7728996276855469 mspe:19.654815673828125 dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           20240702-214842     Model:              iTransformer        

[1mData Loader[0m
  Data:               custom              Root Path:          /home/qc/twj/ml_data/data2/
  Data Path:          #0_hour_residual_ae.csvFeatures:           MS                  
  Target:             residual_ae         Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            720                 Label Len:          360                 
  Pred Len:           360                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             4                   Dec In:             4                   
  C Out:              4                   d model:            128                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               128                 
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                soh-residual_ae-#0  Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_20240702-214842_iTransformer_custom_ftMS_sl720_ll360_pl360_dm128_nh8_el2_dl1_df128_expand2_dc4_fc3_ebtimeF_dtTrue_soh-residual_ae-#0_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 9152
val 1104
test 2564
======================================================================
Layer (type:depth-idx)                        Param #
======================================================================
Model                                         --
â”œâ”€DataEmbedding_inverted: 1-1                 --
â”‚    â””â”€Linear: 2-1                            92,288
â”‚    â””â”€Dropout: 2-2                           --
â”œâ”€Encoder: 1-2                                --
â”‚    â””â”€ModuleList: 2-3                        --
â”‚    â”‚    â””â”€EncoderLayer: 3-1                 99,584
â”‚    â”‚    â””â”€EncoderLayer: 3-2                 99,584
â”‚    â””â”€LayerNorm: 2-4                         256
â”œâ”€Linear: 1-3                                 46,440
======================================================================
Total params: 338,152
Trainable params: 338,152
Non-trainable params: 0
======================================================================
	iters: 57, epoch: 1 | loss: 0.3089212
	speed: 0.0289s/iter; left time: 81.1654s
	iters: 114, epoch: 1 | loss: 0.1692154
	speed: 0.0059s/iter; left time: 16.3271s
	iters: 171, epoch: 1 | loss: 0.0886193
	speed: 0.0059s/iter; left time: 15.8019s
	iters: 228, epoch: 1 | loss: 0.0569057
	speed: 0.0056s/iter; left time: 14.6266s
	iters: 285, epoch: 1 | loss: 0.0280155
	speed: 0.0053s/iter; left time: 13.6014s
Epoch: 1 cost time: 2.9837517738342285
Epoch: 1, Steps: 286 | Train Loss: 0.1443434 Vali Loss: 0.0010709 Test Loss: 0.0418708
Validation loss decreased (inf --> 0.001071).  Saving model ...
Updating learning rate to 0.0001
	iters: 57, epoch: 2 | loss: 0.0745286
	speed: 0.0243s/iter; left time: 61.1661s
	iters: 114, epoch: 2 | loss: 0.0170654
	speed: 0.0051s/iter; left time: 12.5768s
	iters: 171, epoch: 2 | loss: 0.0488351
	speed: 0.0051s/iter; left time: 12.2841s
	iters: 228, epoch: 2 | loss: 0.0258859
	speed: 0.0051s/iter; left time: 12.0141s
	iters: 285, epoch: 2 | loss: 0.0329886
	speed: 0.0050s/iter; left time: 11.5493s
Epoch: 2 cost time: 1.7631516456604004
Epoch: 2, Steps: 286 | Train Loss: 0.0352588 Vali Loss: 0.0019266 Test Loss: 0.0225454
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 57, epoch: 3 | loss: 0.0311034
	speed: 0.0254s/iter; left time: 56.7205s
	iters: 114, epoch: 3 | loss: 0.0447889
	speed: 0.0054s/iter; left time: 11.6617s
	iters: 171, epoch: 3 | loss: 0.0203379
	speed: 0.0054s/iter; left time: 11.4181s
	iters: 228, epoch: 3 | loss: 0.0237406
	speed: 0.0057s/iter; left time: 11.7216s
	iters: 285, epoch: 3 | loss: 0.0368563
	speed: 0.0053s/iter; left time: 10.7033s
Epoch: 3 cost time: 1.851456642150879
Epoch: 3, Steps: 286 | Train Loss: 0.0235930 Vali Loss: 0.0022590 Test Loss: 0.0187925
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
	iters: 57, epoch: 4 | loss: 0.0210172
	speed: 0.0275s/iter; left time: 53.4474s
	iters: 114, epoch: 4 | loss: 0.0286390
	speed: 0.0060s/iter; left time: 11.2852s
	iters: 171, epoch: 4 | loss: 0.0262664
	speed: 0.0054s/iter; left time: 9.8289s
	iters: 228, epoch: 4 | loss: 0.0279210
	speed: 0.0051s/iter; left time: 8.9658s
	iters: 285, epoch: 4 | loss: 0.0219876
	speed: 0.0049s/iter; left time: 8.4947s
Epoch: 4 cost time: 1.9361343383789062
Epoch: 4, Steps: 286 | Train Loss: 0.0197078 Vali Loss: 0.0018835 Test Loss: 0.0167974
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_20240702-214842_iTransformer_custom_ftMS_sl720_ll360_pl360_dm128_nh8_el2_dl1_df128_expand2_dc4_fc3_ebtimeF_dtTrue_soh-residual_ae-#0_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2564
test shape: (80, 32, 360, 1) (80, 32, 360, 1)
test shape: (2560, 360, 1) (2560, 360, 1)
mae:0.1558450609445572 mse:0.041870784014463425 rmse:0.2046235203742981 mape:0.3199586570262909 mspe:30.008092880249023 dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           20240702-214857     Model:              Autoformer          

[1mData Loader[0m
  Data:               custom              Root Path:          /home/qc/twj/ml_data/data2/
  Data Path:          #0_hour_residual_ae.csvFeatures:           MS                  
  Target:             residual_ae         Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            720                 Label Len:          360                 
  Pred Len:           360                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             4                   Dec In:             4                   
  C Out:              4                   d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         16                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                soh-residual_ae-#0  Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_20240702-214857_Autoformer_custom_ftMS_sl720_ll360_pl360_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_soh-residual_ae-#0_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 9152
val 1104
test 2564
===========================================================================
Layer (type:depth-idx)                             Param #
===========================================================================
Model                                              --
â”œâ”€series_decomp: 1-1                               --
â”‚    â””â”€moving_avg: 2-1                             --
â”‚    â”‚    â””â”€AvgPool1d: 3-1                         --
â”œâ”€DataEmbedding_wo_pos: 1-2                        --
â”‚    â””â”€TokenEmbedding: 2-2                         --
â”‚    â”‚    â””â”€Conv1d: 3-2                            6,144
â”‚    â””â”€PositionalEmbedding: 2-3                    --
â”‚    â””â”€TimeFeatureEmbedding: 2-4                   --
â”‚    â”‚    â””â”€Linear: 3-3                            2,048
â”‚    â””â”€Dropout: 2-5                                --
â”œâ”€Encoder: 1-3                                     --
â”‚    â””â”€ModuleList: 2-6                             --
â”‚    â”‚    â””â”€EncoderLayer: 3-4                      3,147,776
â”‚    â”‚    â””â”€EncoderLayer: 3-5                      3,147,776
â”‚    â””â”€my_Layernorm: 2-7                           --
â”‚    â”‚    â””â”€LayerNorm: 3-6                         1,024
â”œâ”€DataEmbedding_wo_pos: 1-4                        --
â”‚    â””â”€TokenEmbedding: 2-8                         --
â”‚    â”‚    â””â”€Conv1d: 3-7                            6,144
â”‚    â””â”€PositionalEmbedding: 2-9                    --
â”‚    â””â”€TimeFeatureEmbedding: 2-10                  --
â”‚    â”‚    â””â”€Linear: 3-8                            2,048
â”‚    â””â”€Dropout: 2-11                               --
â”œâ”€Decoder: 1-5                                     --
â”‚    â””â”€ModuleList: 2-12                            --
â”‚    â”‚    â””â”€DecoderLayer: 3-9                      4,204,544
â”‚    â””â”€my_Layernorm: 2-13                          --
â”‚    â”‚    â””â”€LayerNorm: 3-10                        1,024
â”‚    â””â”€Linear: 2-14                                2,052
===========================================================================
Total params: 10,520,580
Trainable params: 10,520,580
Non-trainable params: 0
===========================================================================
	iters: 114, epoch: 1 | loss: 0.4002035
	speed: 0.1579s/iter; left time: 885.2066s
	iters: 228, epoch: 1 | loss: 0.2333201
	speed: 0.1455s/iter; left time: 799.3121s
	iters: 342, epoch: 1 | loss: 0.1141372
	speed: 0.1456s/iter; left time: 783.2350s
	iters: 456, epoch: 1 | loss: 0.0756334
	speed: 0.1456s/iter; left time: 766.8011s
	iters: 570, epoch: 1 | loss: 0.2279118
	speed: 0.1457s/iter; left time: 750.3331s
Epoch: 1 cost time: 84.76866102218628
Epoch: 1, Steps: 572 | Train Loss: 0.2859008 Vali Loss: 11.7970505 Test Loss: 11.2985592
Validation loss decreased (inf --> 11.797050).  Saving model ...
Updating learning rate to 0.0001
	iters: 114, epoch: 2 | loss: 0.1036601
	speed: 0.3809s/iter; left time: 1918.0254s
	iters: 228, epoch: 2 | loss: 0.1113085
	speed: 0.1456s/iter; left time: 716.5848s
	iters: 342, epoch: 2 | loss: 0.1270420
	speed: 0.1457s/iter; left time: 700.3649s
	iters: 456, epoch: 2 | loss: 0.0739722
	speed: 0.1457s/iter; left time: 683.8654s
	iters: 570, epoch: 2 | loss: 0.0435780
	speed: 0.1457s/iter; left time: 667.1816s
Epoch: 2 cost time: 83.55931830406189
Epoch: 2, Steps: 572 | Train Loss: 0.0845867 Vali Loss: 2.1358099 Test Loss: 1.8193142
Validation loss decreased (11.797050 --> 2.135810).  Saving model ...
Updating learning rate to 5e-05
	iters: 114, epoch: 3 | loss: 0.0621669
	speed: 0.3810s/iter; left time: 1700.5842s
	iters: 228, epoch: 3 | loss: 0.0540262
	speed: 0.1457s/iter; left time: 633.5681s
	iters: 342, epoch: 3 | loss: 0.0532392
	speed: 0.1458s/iter; left time: 617.2948s
	iters: 456, epoch: 3 | loss: 0.0474990
	speed: 0.1457s/iter; left time: 600.3703s
	iters: 570, epoch: 3 | loss: 0.0429989
	speed: 0.1457s/iter; left time: 583.9737s
Epoch: 3 cost time: 83.58595275878906
Epoch: 3, Steps: 572 | Train Loss: 0.0463540 Vali Loss: 2.1566846 Test Loss: 1.7786052
EarlyStopping counter: 1 out of 3
Updating learning rate to 2.5e-05
	iters: 114, epoch: 4 | loss: 0.0417626
	speed: 0.3811s/iter; left time: 1483.0540s
	iters: 228, epoch: 4 | loss: 0.0451982
	speed: 0.1457s/iter; left time: 550.2990s
	iters: 342, epoch: 4 | loss: 0.0555557
	speed: 0.1457s/iter; left time: 533.6241s
	iters: 456, epoch: 4 | loss: 0.0249248
	speed: 0.1457s/iter; left time: 517.1619s
	iters: 570, epoch: 4 | loss: 0.0311122
	speed: 0.1458s/iter; left time: 500.6865s
Epoch: 4 cost time: 83.59290742874146
Epoch: 4, Steps: 572 | Train Loss: 0.0397896 Vali Loss: 2.0514829 Test Loss: 1.5971782
Validation loss decreased (2.135810 --> 2.051483).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 114, epoch: 5 | loss: 0.0324871
	speed: 0.3820s/iter; left time: 1267.7684s
	iters: 228, epoch: 5 | loss: 0.0398700
	speed: 0.1457s/iter; left time: 466.8335s
	iters: 342, epoch: 5 | loss: 0.0512398
	speed: 0.1457s/iter; left time: 450.3361s
	iters: 456, epoch: 5 | loss: 0.0323721
	speed: 0.1458s/iter; left time: 433.8978s
	iters: 570, epoch: 5 | loss: 0.0330287
	speed: 0.1457s/iter; left time: 417.2690s
Epoch: 5 cost time: 83.59857869148254
Epoch: 5, Steps: 572 | Train Loss: 0.0366384 Vali Loss: 2.1585934 Test Loss: 1.6797979
EarlyStopping counter: 1 out of 3
Updating learning rate to 6.25e-06
	iters: 114, epoch: 6 | loss: 0.0237933
	speed: 0.3812s/iter; left time: 1047.0769s
	iters: 228, epoch: 6 | loss: 0.0296588
	speed: 0.1456s/iter; left time: 383.4348s
	iters: 342, epoch: 6 | loss: 0.0350205
	speed: 0.1457s/iter; left time: 366.9643s
	iters: 456, epoch: 6 | loss: 0.0285328
	speed: 0.1457s/iter; left time: 350.4779s
	iters: 570, epoch: 6 | loss: 0.0473282
	speed: 0.1457s/iter; left time: 333.8518s
Epoch: 6 cost time: 83.57122945785522
Epoch: 6, Steps: 572 | Train Loss: 0.0353057 Vali Loss: 2.2268808 Test Loss: 1.7402834
EarlyStopping counter: 2 out of 3
Updating learning rate to 3.125e-06
	iters: 114, epoch: 7 | loss: 0.0571918
	speed: 0.3811s/iter; left time: 828.8994s
	iters: 228, epoch: 7 | loss: 0.0365185
	speed: 0.1457s/iter; left time: 300.2384s
	iters: 342, epoch: 7 | loss: 0.0422482
	speed: 0.1457s/iter; left time: 283.6649s
	iters: 456, epoch: 7 | loss: 0.0269827
	speed: 0.1457s/iter; left time: 267.1423s
	iters: 570, epoch: 7 | loss: 0.0314442
	speed: 0.1457s/iter; left time: 250.4718s
Epoch: 7 cost time: 83.58582782745361
Epoch: 7, Steps: 572 | Train Loss: 0.0343396 Vali Loss: 2.1435406 Test Loss: 1.6782820
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_20240702-214857_Autoformer_custom_ftMS_sl720_ll360_pl360_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_soh-residual_ae-#0_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2564
test shape: (160, 16, 360, 1) (160, 16, 360, 1)
test shape: (2560, 360, 1) (2560, 360, 1)
mae:1.180954098701477 mse:1.5971781015396118 rmse:1.2637951374053955 mape:1.4319223165512085 mspe:22.285112380981445 dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           20240702-220209     Model:              FEDformer           

[1mData Loader[0m
  Data:               custom              Root Path:          /home/qc/twj/ml_data/data2/
  Data Path:          #0_hour_residual_ae.csvFeatures:           MS                  
  Target:             residual_ae         Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            720                 Label Len:          360                 
  Pred Len:           360                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             4                   Dec In:             4                   
  C Out:              4                   d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         16                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                soh-residual_ae-#0  Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
fourier enhanced block used!
modes=32, index=[0, 6, 15, 22, 28, 36, 37, 58, 64, 88, 106, 108, 113, 118, 131, 140, 167, 175, 179, 199, 216, 226, 258, 260, 269, 273, 285, 301, 325, 332, 343, 352]
fourier enhanced block used!
modes=32, index=[9, 16, 18, 20, 28, 32, 40, 46, 74, 76, 79, 85, 92, 104, 107, 127, 193, 208, 210, 212, 215, 222, 232, 236, 238, 252, 257, 284, 287, 313, 344, 352]
 fourier enhanced cross attention used!
modes_q=32, index_q=[12, 13, 17, 22, 25, 31, 58, 61, 84, 86, 96, 100, 116, 127, 128, 137, 139, 162, 174, 182, 191, 201, 213, 229, 239, 246, 266, 298, 310, 336, 350, 356]
modes_kv=32, index_kv=[13, 17, 21, 32, 40, 49, 51, 53, 91, 93, 108, 112, 154, 170, 176, 193, 210, 217, 219, 235, 273, 278, 279, 290, 294, 297, 299, 324, 341, 352, 354, 357]
>>>>>>>start training : long_term_forecast_20240702-220209_FEDformer_custom_ftMS_sl720_ll360_pl360_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_soh-residual_ae-#0_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 9152
val 1104
test 2564
================================================================================
Layer (type:depth-idx)                                  Param #
================================================================================
Model                                                   --
â”œâ”€series_decomp: 1-1                                    --
â”‚    â””â”€moving_avg: 2-1                                  --
â”‚    â”‚    â””â”€AvgPool1d: 3-1                              --
â”œâ”€DataEmbedding: 1-2                                    --
â”‚    â””â”€TokenEmbedding: 2-2                              --
â”‚    â”‚    â””â”€Conv1d: 3-2                                 6,144
â”‚    â””â”€PositionalEmbedding: 2-3                         --
â”‚    â””â”€TimeFeatureEmbedding: 2-4                        --
â”‚    â”‚    â””â”€Linear: 3-3                                 2,048
â”‚    â””â”€Dropout: 2-5                                     --
â”œâ”€DataEmbedding: 1-3                                    --
â”‚    â””â”€TokenEmbedding: 2-6                              --
â”‚    â”‚    â””â”€Conv1d: 3-4                                 6,144
â”‚    â””â”€PositionalEmbedding: 2-7                         --
â”‚    â””â”€TimeFeatureEmbedding: 2-8                        --
â”‚    â”‚    â””â”€Linear: 3-5                                 2,048
â”‚    â””â”€Dropout: 2-9                                     --
â”œâ”€Encoder: 1-4                                          --
â”‚    â””â”€ModuleList: 2-10                                 --
â”‚    â”‚    â””â”€EncoderLayer: 3-6                           5,244,928
â”‚    â”‚    â””â”€EncoderLayer: 3-7                           5,244,928
â”‚    â””â”€my_Layernorm: 2-11                               --
â”‚    â”‚    â””â”€LayerNorm: 3-8                              1,024
â”œâ”€Decoder: 1-5                                          --
â”‚    â””â”€ModuleList: 2-12                                 --
â”‚    â”‚    â””â”€DecoderLayer: 3-9                           8,398,848
â”‚    â””â”€my_Layernorm: 2-13                               --
â”‚    â”‚    â””â”€LayerNorm: 3-10                             1,024
â”‚    â””â”€Linear: 2-14                                     2,052
================================================================================
Total params: 18,909,188
Trainable params: 18,909,188
Non-trainable params: 0
================================================================================
	iters: 114, epoch: 1 | loss: 0.7874247
	speed: 0.2055s/iter; left time: 1152.0241s
	iters: 228, epoch: 1 | loss: 0.4127692
	speed: 0.1941s/iter; left time: 1066.3473s
	iters: 342, epoch: 1 | loss: 0.3730431
	speed: 0.1940s/iter; left time: 1043.3130s
	iters: 456, epoch: 1 | loss: 0.2125379
	speed: 0.1951s/iter; left time: 1027.1141s
	iters: 570, epoch: 1 | loss: 0.2340602
	speed: 0.1943s/iter; left time: 1000.8566s
Epoch: 1 cost time: 112.61112546920776
Epoch: 1, Steps: 572 | Train Loss: 0.3345257 Vali Loss: 0.3764994 Test Loss: 0.2457309
Validation loss decreased (inf --> 0.376499).  Saving model ...
Updating learning rate to 0.0001
	iters: 114, epoch: 2 | loss: 0.2512118
	speed: 0.2708s/iter; left time: 1363.3603s
	iters: 228, epoch: 2 | loss: 0.3786165
	speed: 0.1947s/iter; left time: 958.0357s
	iters: 342, epoch: 2 | loss: 0.2119192
	speed: 0.1950s/iter; left time: 937.4159s
	iters: 456, epoch: 2 | loss: 0.5400285
	speed: 0.1947s/iter; left time: 913.7110s
	iters: 570, epoch: 2 | loss: 0.0763105
	speed: 0.1961s/iter; left time: 897.9595s
Epoch: 2 cost time: 111.90827488899231
Epoch: 2, Steps: 572 | Train Loss: 0.2698713 Vali Loss: 0.5035239 Test Loss: 0.2722069
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 114, epoch: 3 | loss: 0.1210739
	speed: 0.2703s/iter; left time: 1206.3805s
	iters: 228, epoch: 3 | loss: 0.0247975
	speed: 0.1958s/iter; left time: 851.4357s
	iters: 342, epoch: 3 | loss: 0.0102148
	speed: 0.1948s/iter; left time: 825.0375s
	iters: 456, epoch: 3 | loss: 0.0164886
	speed: 0.1948s/iter; left time: 802.8674s
	iters: 570, epoch: 3 | loss: 0.0216971
	speed: 0.1948s/iter; left time: 780.5451s
Epoch: 3 cost time: 111.86517643928528
Epoch: 3, Steps: 572 | Train Loss: 0.0356077 Vali Loss: 0.2348821 Test Loss: 0.3605923
Validation loss decreased (0.376499 --> 0.234882).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 114, epoch: 4 | loss: 0.0193308
	speed: 0.2749s/iter; left time: 1069.7546s
	iters: 228, epoch: 4 | loss: 0.0182232
	speed: 0.1964s/iter; left time: 741.7949s
	iters: 342, epoch: 4 | loss: 0.0265897
	speed: 0.1947s/iter; left time: 713.1863s
	iters: 456, epoch: 4 | loss: 0.0260074
	speed: 0.1945s/iter; left time: 690.3703s
	iters: 570, epoch: 4 | loss: 0.0102938
	speed: 0.1944s/iter; left time: 667.7697s
Epoch: 4 cost time: 112.06927371025085
Epoch: 4, Steps: 572 | Train Loss: 0.0195679 Vali Loss: 0.5820721 Test Loss: 0.5877734
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.25e-05
	iters: 114, epoch: 5 | loss: 0.0174568
	speed: 0.2733s/iter; left time: 907.0948s
	iters: 228, epoch: 5 | loss: 0.0158574
	speed: 0.1974s/iter; left time: 632.5524s
	iters: 342, epoch: 5 | loss: 0.0178085
	speed: 0.1953s/iter; left time: 603.6074s
	iters: 456, epoch: 5 | loss: 0.0169264
	speed: 0.1947s/iter; left time: 579.5283s
	iters: 570, epoch: 5 | loss: 0.0134622
	speed: 0.1947s/iter; left time: 557.3637s
Epoch: 5 cost time: 112.33835077285767
Epoch: 5, Steps: 572 | Train Loss: 0.0170105 Vali Loss: 0.5041531 Test Loss: 0.5400935
EarlyStopping counter: 2 out of 3
Updating learning rate to 6.25e-06
	iters: 114, epoch: 6 | loss: 0.0085373
	speed: 0.2686s/iter; left time: 737.9503s
	iters: 228, epoch: 6 | loss: 0.0205024
	speed: 0.1948s/iter; left time: 512.7915s
	iters: 342, epoch: 6 | loss: 0.0154425
	speed: 0.1948s/iter; left time: 490.6532s
	iters: 456, epoch: 6 | loss: 0.0148379
	speed: 0.1948s/iter; left time: 468.4028s
	iters: 570, epoch: 6 | loss: 0.0200686
	speed: 0.1947s/iter; left time: 446.0489s
Epoch: 6 cost time: 111.676931142807
Epoch: 6, Steps: 572 | Train Loss: 0.0156681 Vali Loss: 0.4565018 Test Loss: 0.5050436
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_20240702-220209_FEDformer_custom_ftMS_sl720_ll360_pl360_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_soh-residual_ae-#0_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2564
test shape: (160, 16, 360, 1) (160, 16, 360, 1)
test shape: (2560, 360, 1) (2560, 360, 1)
mae:0.49194419384002686 mse:0.3605923056602478 rmse:0.6004933714866638 mape:0.6619082093238831 mspe:29.562732696533203 dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           20240702-221418     Model:              PatchTST            

[1mData Loader[0m
  Data:               custom              Root Path:          /home/qc/twj/ml_data/data2/
  Data Path:          #0_hour_residual_ae.csvFeatures:           MS                  
  Target:             residual_ae         Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            720                 Label Len:          360                 
  Pred Len:           360                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             4                   Dec In:             4                   
  C Out:              4                   d model:            512                 
  n heads:            2                   e layers:           1                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                soh-residual_ae-#0  Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_20240702-221418_PatchTST_custom_ftMS_sl720_ll360_pl360_dm512_nh2_el1_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_soh-residual_ae-#0_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 9152
val 1104
test 2564
======================================================================
Layer (type:depth-idx)                        Param #
======================================================================
Model                                         --
â”œâ”€PatchEmbedding: 1-1                         --
â”‚    â””â”€ReplicationPad1d: 2-1                  --
â”‚    â””â”€Linear: 2-2                            8,192
â”‚    â””â”€PositionalEmbedding: 2-3               --
â”‚    â””â”€Dropout: 2-4                           --
â”œâ”€Encoder: 1-2                                --
â”‚    â””â”€ModuleList: 2-5                        --
â”‚    â”‚    â””â”€EncoderLayer: 3-1                 3,152,384
â”‚    â””â”€Sequential: 2-6                        --
â”‚    â”‚    â””â”€Transpose: 3-2                    --
â”‚    â”‚    â””â”€BatchNorm1d: 3-3                  1,024
â”‚    â”‚    â””â”€Transpose: 3-4                    --
â”œâ”€FlattenHead: 1-3                            --
â”‚    â””â”€Flatten: 2-7                           --
â”‚    â””â”€Linear: 2-8                            16,589,160
â”‚    â””â”€Dropout: 2-9                           --
======================================================================
Total params: 19,750,760
Trainable params: 19,750,760
Non-trainable params: 0
======================================================================
	iters: 57, epoch: 1 | loss: 0.1139565
	speed: 0.0501s/iter; left time: 140.5059s
	iters: 114, epoch: 1 | loss: 0.0609207
	speed: 0.0243s/iter; left time: 66.6397s
	iters: 171, epoch: 1 | loss: 0.0435504
	speed: 0.0243s/iter; left time: 65.3052s
	iters: 228, epoch: 1 | loss: 0.0731530
	speed: 0.0242s/iter; left time: 63.7361s
	iters: 285, epoch: 1 | loss: 0.0727297
	speed: 0.0242s/iter; left time: 62.3397s
Epoch: 1 cost time: 8.429908990859985
Epoch: 1, Steps: 286 | Train Loss: 0.0743822 Vali Loss: 0.0109129 Test Loss: 0.0197546
Validation loss decreased (inf --> 0.010913).  Saving model ...
Updating learning rate to 0.0001
	iters: 57, epoch: 2 | loss: 0.0629459
	speed: 0.0579s/iter; left time: 145.7725s
	iters: 114, epoch: 2 | loss: 0.0408792
	speed: 0.0242s/iter; left time: 59.5835s
	iters: 171, epoch: 2 | loss: 0.0720428
	speed: 0.0242s/iter; left time: 58.2389s
	iters: 228, epoch: 2 | loss: 0.0476878
	speed: 0.0242s/iter; left time: 56.8159s
	iters: 285, epoch: 2 | loss: 0.0434417
	speed: 0.0242s/iter; left time: 55.4421s
Epoch: 2 cost time: 7.207524061203003
Epoch: 2, Steps: 286 | Train Loss: 0.0589936 Vali Loss: 0.0030754 Test Loss: 0.0054512
Validation loss decreased (0.010913 --> 0.003075).  Saving model ...
Updating learning rate to 5e-05
	iters: 57, epoch: 3 | loss: 0.0516430
	speed: 0.0583s/iter; left time: 130.2189s
	iters: 114, epoch: 3 | loss: 0.0439028
	speed: 0.0242s/iter; left time: 52.6563s
	iters: 171, epoch: 3 | loss: 0.0552054
	speed: 0.0242s/iter; left time: 51.3212s
	iters: 228, epoch: 3 | loss: 0.0382218
	speed: 0.0242s/iter; left time: 49.9206s
	iters: 285, epoch: 3 | loss: 0.0358856
	speed: 0.0242s/iter; left time: 48.5416s
Epoch: 3 cost time: 7.226948976516724
Epoch: 3, Steps: 286 | Train Loss: 0.0506435 Vali Loss: 0.0050937 Test Loss: 0.0064172
EarlyStopping counter: 1 out of 3
Updating learning rate to 2.5e-05
	iters: 57, epoch: 4 | loss: 0.0450208
	speed: 0.0579s/iter; left time: 112.6144s
	iters: 114, epoch: 4 | loss: 0.0387652
	speed: 0.0243s/iter; left time: 45.8404s
	iters: 171, epoch: 4 | loss: 0.0423858
	speed: 0.0243s/iter; left time: 44.4529s
	iters: 228, epoch: 4 | loss: 0.0371702
	speed: 0.0243s/iter; left time: 43.1180s
	iters: 285, epoch: 4 | loss: 0.0547392
	speed: 0.0243s/iter; left time: 41.7052s
Epoch: 4 cost time: 7.275571823120117
Epoch: 4, Steps: 286 | Train Loss: 0.0475536 Vali Loss: 0.0069355 Test Loss: 0.0093005
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.25e-05
	iters: 57, epoch: 5 | loss: 0.0387704
	speed: 0.0570s/iter; left time: 94.5977s
	iters: 114, epoch: 5 | loss: 0.0501978
	speed: 0.0242s/iter; left time: 38.8642s
	iters: 171, epoch: 5 | loss: 0.0470081
	speed: 0.0243s/iter; left time: 37.5401s
	iters: 228, epoch: 5 | loss: 0.0406108
	speed: 0.0243s/iter; left time: 36.1491s
	iters: 285, epoch: 5 | loss: 0.0475680
	speed: 0.0243s/iter; left time: 34.7762s
Epoch: 5 cost time: 7.229588985443115
Epoch: 5, Steps: 286 | Train Loss: 0.0464952 Vali Loss: 0.0037748 Test Loss: 0.0048739
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_20240702-221418_PatchTST_custom_ftMS_sl720_ll360_pl360_dm512_nh2_el1_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_soh-residual_ae-#0_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2564
test shape: (80, 32, 360, 1) (80, 32, 360, 1)
test shape: (2560, 360, 1) (2560, 360, 1)
mae:0.05680409073829651 mse:0.005451234523206949 rmse:0.07383247464895248 mape:0.10784740000963211 mspe:4.452419281005859 dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           20240702-221507     Model:              DLinear             

[1mData Loader[0m
  Data:               custom              Root Path:          /home/qc/twj/ml_data/data2/
  Data Path:          #0_hour_residual_ae.csvFeatures:           MS                  
  Target:             residual_ae         Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            720                 Label Len:          360                 
  Pred Len:           360                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             4                   Dec In:             4                   
  C Out:              4                   d model:            512                 
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               2048                
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                soh-residual_ae-#0  Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_20240702-221507_DLinear_custom_ftMS_sl720_ll360_pl360_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_soh-residual_ae-#0_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 9152
val 1104
test 2564
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
Model                                    --
â”œâ”€series_decomp: 1-1                     --
â”‚    â””â”€moving_avg: 2-1                   --
â”‚    â”‚    â””â”€AvgPool1d: 3-1               --
â”œâ”€Linear: 1-2                            259,560
â”œâ”€Linear: 1-3                            259,560
=================================================================
Total params: 519,120
Trainable params: 519,120
Non-trainable params: 0
=================================================================
	iters: 57, epoch: 1 | loss: 0.0516336
	speed: 0.0239s/iter; left time: 66.9331s
	iters: 114, epoch: 1 | loss: 0.0588699
	speed: 0.0020s/iter; left time: 5.5905s
	iters: 171, epoch: 1 | loss: 0.0594125
	speed: 0.0021s/iter; left time: 5.5214s
	iters: 228, epoch: 1 | loss: 0.0349448
	speed: 0.0020s/iter; left time: 5.1908s
	iters: 285, epoch: 1 | loss: 0.0564908
	speed: 0.0020s/iter; left time: 5.0932s
Epoch: 1 cost time: 1.860318660736084
Epoch: 1, Steps: 286 | Train Loss: 0.0673271 Vali Loss: 0.0013408 Test Loss: 0.0336493
Validation loss decreased (inf --> 0.001341).  Saving model ...
Updating learning rate to 0.0001
	iters: 57, epoch: 2 | loss: 0.0419254
	speed: 0.0207s/iter; left time: 52.1888s
	iters: 114, epoch: 2 | loss: 0.0422714
	speed: 0.0021s/iter; left time: 5.1356s
	iters: 171, epoch: 2 | loss: 0.0189870
	speed: 0.0021s/iter; left time: 5.0524s
	iters: 228, epoch: 2 | loss: 0.0225555
	speed: 0.0020s/iter; left time: 4.8099s
	iters: 285, epoch: 2 | loss: 0.0202291
	speed: 0.0019s/iter; left time: 4.3400s
Epoch: 2 cost time: 0.8580455780029297
Epoch: 2, Steps: 286 | Train Loss: 0.0327712 Vali Loss: 0.0008952 Test Loss: 0.0238594
Validation loss decreased (0.001341 --> 0.000895).  Saving model ...
Updating learning rate to 5e-05
	iters: 57, epoch: 3 | loss: 0.0300042
	speed: 0.0207s/iter; left time: 46.1289s
	iters: 114, epoch: 3 | loss: 0.0372407
	speed: 0.0020s/iter; left time: 4.4033s
	iters: 171, epoch: 3 | loss: 0.0373209
	speed: 0.0020s/iter; left time: 4.2430s
	iters: 228, epoch: 3 | loss: 0.0375762
	speed: 0.0020s/iter; left time: 4.1284s
	iters: 285, epoch: 3 | loss: 0.0215387
	speed: 0.0019s/iter; left time: 3.8487s
Epoch: 3 cost time: 0.8482563495635986
Epoch: 3, Steps: 286 | Train Loss: 0.0270888 Vali Loss: 0.0006589 Test Loss: 0.0238316
Validation loss decreased (0.000895 --> 0.000659).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 57, epoch: 4 | loss: 0.0371346
	speed: 0.0195s/iter; left time: 37.8864s
	iters: 114, epoch: 4 | loss: 0.0295137
	speed: 0.0021s/iter; left time: 3.9462s
	iters: 171, epoch: 4 | loss: 0.0335362
	speed: 0.0021s/iter; left time: 3.8366s
	iters: 228, epoch: 4 | loss: 0.0189646
	speed: 0.0021s/iter; left time: 3.6571s
	iters: 285, epoch: 4 | loss: 0.0215430
	speed: 0.0019s/iter; left time: 3.3150s
Epoch: 4 cost time: 0.871628999710083
Epoch: 4, Steps: 286 | Train Loss: 0.0252441 Vali Loss: 0.0005840 Test Loss: 0.0197557
Validation loss decreased (0.000659 --> 0.000584).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 57, epoch: 5 | loss: 0.0142001
	speed: 0.0218s/iter; left time: 36.1408s
	iters: 114, epoch: 5 | loss: 0.0169912
	speed: 0.0022s/iter; left time: 3.5371s
	iters: 171, epoch: 5 | loss: 0.0260455
	speed: 0.0021s/iter; left time: 3.3012s
	iters: 228, epoch: 5 | loss: 0.0295974
	speed: 0.0021s/iter; left time: 3.1804s
	iters: 285, epoch: 5 | loss: 0.0142772
	speed: 0.0021s/iter; left time: 2.9452s
Epoch: 5 cost time: 0.9047770500183105
Epoch: 5, Steps: 286 | Train Loss: 0.0244535 Vali Loss: 0.0005831 Test Loss: 0.0205107
Validation loss decreased (0.000584 --> 0.000583).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 57, epoch: 6 | loss: 0.0221465
	speed: 0.0208s/iter; left time: 28.6180s
	iters: 114, epoch: 6 | loss: 0.0133731
	speed: 0.0021s/iter; left time: 2.7383s
	iters: 171, epoch: 6 | loss: 0.0291724
	speed: 0.0020s/iter; left time: 2.5303s
	iters: 228, epoch: 6 | loss: 0.0244009
	speed: 0.0020s/iter; left time: 2.4019s
	iters: 285, epoch: 6 | loss: 0.0250270
	speed: 0.0020s/iter; left time: 2.2778s
Epoch: 6 cost time: 0.8655805587768555
Epoch: 6, Steps: 286 | Train Loss: 0.0240671 Vali Loss: 0.0005524 Test Loss: 0.0198808
Validation loss decreased (0.000583 --> 0.000552).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 57, epoch: 7 | loss: 0.0318550
	speed: 0.0207s/iter; left time: 22.4849s
	iters: 114, epoch: 7 | loss: 0.0176412
	speed: 0.0021s/iter; left time: 2.1918s
	iters: 171, epoch: 7 | loss: 0.0299980
	speed: 0.0021s/iter; left time: 2.0480s
	iters: 228, epoch: 7 | loss: 0.0242263
	speed: 0.0021s/iter; left time: 1.9323s
	iters: 285, epoch: 7 | loss: 0.0201691
	speed: 0.0021s/iter; left time: 1.7632s
Epoch: 7 cost time: 0.879676103591919
Epoch: 7, Steps: 286 | Train Loss: 0.0238442 Vali Loss: 0.0005121 Test Loss: 0.0192932
Validation loss decreased (0.000552 --> 0.000512).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 57, epoch: 8 | loss: 0.0210902
	speed: 0.0209s/iter; left time: 16.7428s
	iters: 114, epoch: 8 | loss: 0.0131845
	speed: 0.0021s/iter; left time: 1.5334s
	iters: 171, epoch: 8 | loss: 0.0146953
	speed: 0.0020s/iter; left time: 1.4102s
	iters: 228, epoch: 8 | loss: 0.0269039
	speed: 0.0021s/iter; left time: 1.3064s
	iters: 285, epoch: 8 | loss: 0.0478088
	speed: 0.0020s/iter; left time: 1.1209s
Epoch: 8 cost time: 0.8862268924713135
Epoch: 8, Steps: 286 | Train Loss: 0.0237337 Vali Loss: 0.0005090 Test Loss: 0.0190847
Validation loss decreased (0.000512 --> 0.000509).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 57, epoch: 9 | loss: 0.0209473
	speed: 0.0208s/iter; left time: 10.7545s
	iters: 114, epoch: 9 | loss: 0.0194256
	speed: 0.0021s/iter; left time: 0.9807s
	iters: 171, epoch: 9 | loss: 0.0258648
	speed: 0.0021s/iter; left time: 0.8582s
	iters: 228, epoch: 9 | loss: 0.0204872
	speed: 0.0021s/iter; left time: 0.7338s
	iters: 285, epoch: 9 | loss: 0.0285131
	speed: 0.0020s/iter; left time: 0.5874s
Epoch: 9 cost time: 0.8913099765777588
Epoch: 9, Steps: 286 | Train Loss: 0.0236885 Vali Loss: 0.0005363 Test Loss: 0.0194138
EarlyStopping counter: 1 out of 3
Updating learning rate to 3.90625e-07
	iters: 57, epoch: 10 | loss: 0.0254866
	speed: 0.0205s/iter; left time: 4.7127s
	iters: 114, epoch: 10 | loss: 0.0307283
	speed: 0.0020s/iter; left time: 0.3536s
	iters: 171, epoch: 10 | loss: 0.0243368
	speed: 0.0020s/iter; left time: 0.2319s
	iters: 228, epoch: 10 | loss: 0.0289935
	speed: 0.0020s/iter; left time: 0.1174s
	iters: 285, epoch: 10 | loss: 0.0172788
	speed: 0.0019s/iter; left time: 0.0038s
Epoch: 10 cost time: 0.8447132110595703
Epoch: 10, Steps: 286 | Train Loss: 0.0236602 Vali Loss: 0.0005326 Test Loss: 0.0192909
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.953125e-07
>>>>>>>testing : long_term_forecast_20240702-221507_DLinear_custom_ftMS_sl720_ll360_pl360_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_soh-residual_ae-#0_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2564
test shape: (80, 32, 360, 1) (80, 32, 360, 1)
test shape: (2560, 360, 1) (2560, 360, 1)
mae:0.08763960748910904 mse:0.019084658473730087 rmse:0.138147234916687 mape:0.13642872869968414 mspe:1.516762375831604 dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           20240702-221527     Model:              TimesNet            

[1mData Loader[0m
  Data:               custom              Root Path:          /home/qc/twj/ml_data/data2/
  Data Path:          #0_hour_residual_ae.csvFeatures:           MS                  
  Target:             residual_ae         Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            720                 Label Len:          360                 
  Pred Len:           360                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             4                   Dec In:             4                   
  C Out:              4                   d model:            16                  
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               32                  
  Moving Avg:         25                  Factor:             3                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           3                   Learning Rate:      0.0001              
  Des:                soh-residual_ae-#0  Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_20240702-221527_TimesNet_custom_ftMS_sl720_ll360_pl360_dm16_nh8_el2_dl1_df32_expand2_dc4_fc3_ebtimeF_dtTrue_soh-residual_ae-#0_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 9152
val 1104
test 2564
======================================================================
Layer (type:depth-idx)                        Param #
======================================================================
Model                                         --
â”œâ”€ModuleList: 1-1                             --
â”‚    â””â”€TimesBlock: 2-1                        --
â”‚    â”‚    â””â”€Sequential: 3-1                   293,152
â”‚    â””â”€TimesBlock: 2-2                        --
â”‚    â”‚    â””â”€Sequential: 3-2                   293,152
â”œâ”€DataEmbedding: 1-2                          --
â”‚    â””â”€TokenEmbedding: 2-3                    --
â”‚    â”‚    â””â”€Conv1d: 3-3                       192
â”‚    â””â”€PositionalEmbedding: 2-4               --
â”‚    â””â”€TimeFeatureEmbedding: 2-5              --
â”‚    â”‚    â””â”€Linear: 3-4                       64
â”‚    â””â”€Dropout: 2-6                           --
â”œâ”€LayerNorm: 1-3                              32
â”œâ”€Linear: 1-4                                 778,680
â”œâ”€Linear: 1-5                                 68
======================================================================
Total params: 1,365,340
Trainable params: 1,365,340
Non-trainable params: 0
======================================================================
	iters: 57, epoch: 1 | loss: 0.1023809
	speed: 0.1453s/iter; left time: 407.4924s
	iters: 114, epoch: 1 | loss: 0.0685798
	speed: 0.1185s/iter; left time: 325.5647s
	iters: 171, epoch: 1 | loss: 0.0916855
	speed: 0.1185s/iter; left time: 318.8379s
	iters: 228, epoch: 1 | loss: 0.0791013
	speed: 0.1186s/iter; left time: 312.1623s
	iters: 285, epoch: 1 | loss: 0.0766102
	speed: 0.1283s/iter; left time: 330.4469s
Epoch: 1 cost time: 36.07134485244751
Epoch: 1, Steps: 286 | Train Loss: 0.1085125 Vali Loss: 0.0015338 Test Loss: 0.0619818
Validation loss decreased (inf --> 0.001534).  Saving model ...
Updating learning rate to 0.0001
	iters: 57, epoch: 2 | loss: 0.0860338
	speed: 0.2540s/iter; left time: 639.5720s
	iters: 114, epoch: 2 | loss: 0.0427948
	speed: 0.1223s/iter; left time: 301.0187s
	iters: 171, epoch: 2 | loss: 0.0352996
	speed: 0.1222s/iter; left time: 293.8106s
	iters: 228, epoch: 2 | loss: 0.0268238
	speed: 0.1222s/iter; left time: 286.8389s
	iters: 285, epoch: 2 | loss: 0.0382495
	speed: 0.1221s/iter; left time: 279.6172s
Epoch: 2 cost time: 35.765580892562866
Epoch: 2, Steps: 286 | Train Loss: 0.0658888 Vali Loss: 0.0005640 Test Loss: 0.0457690
Validation loss decreased (0.001534 --> 0.000564).  Saving model ...
Updating learning rate to 5e-05
	iters: 57, epoch: 3 | loss: 0.0522659
	speed: 0.2427s/iter; left time: 541.7607s
	iters: 114, epoch: 3 | loss: 0.0476711
	speed: 0.1223s/iter; left time: 266.0273s
	iters: 171, epoch: 3 | loss: 0.0134619
	speed: 0.1222s/iter; left time: 258.8818s
	iters: 228, epoch: 3 | loss: 0.0380047
	speed: 0.1222s/iter; left time: 251.8348s
	iters: 285, epoch: 3 | loss: 0.0293460
	speed: 0.1222s/iter; left time: 244.8705s
Epoch: 3 cost time: 35.23003554344177
Epoch: 3, Steps: 286 | Train Loss: 0.0471199 Vali Loss: 0.0009102 Test Loss: 0.0409340
EarlyStopping counter: 1 out of 3
Updating learning rate to 2.5e-05
	iters: 57, epoch: 4 | loss: 0.0392780
	speed: 0.2424s/iter; left time: 471.6900s
	iters: 114, epoch: 4 | loss: 0.0462656
	speed: 0.1222s/iter; left time: 230.9023s
	iters: 171, epoch: 4 | loss: 0.0236638
	speed: 0.1222s/iter; left time: 223.9117s
	iters: 228, epoch: 4 | loss: 0.0496732
	speed: 0.1222s/iter; left time: 216.9651s
	iters: 285, epoch: 4 | loss: 0.0254325
	speed: 0.1222s/iter; left time: 209.9735s
Epoch: 4 cost time: 35.23967671394348
Epoch: 4, Steps: 286 | Train Loss: 0.0416276 Vali Loss: 0.0009419 Test Loss: 0.0385244
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.25e-05
	iters: 57, epoch: 5 | loss: 0.0495819
	speed: 0.2429s/iter; left time: 403.2177s
	iters: 114, epoch: 5 | loss: 0.0346361
	speed: 0.1222s/iter; left time: 195.9128s
	iters: 171, epoch: 5 | loss: 0.0285386
	speed: 0.1222s/iter; left time: 188.9571s
	iters: 228, epoch: 5 | loss: 0.0486662
	speed: 0.1222s/iter; left time: 181.9857s
	iters: 285, epoch: 5 | loss: 0.0460705
	speed: 0.1222s/iter; left time: 175.0027s
Epoch: 5 cost time: 35.23019242286682
Epoch: 5, Steps: 286 | Train Loss: 0.0392387 Vali Loss: 0.0011555 Test Loss: 0.0375837
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : long_term_forecast_20240702-221527_TimesNet_custom_ftMS_sl720_ll360_pl360_dm16_nh8_el2_dl1_df32_expand2_dc4_fc3_ebtimeF_dtTrue_soh-residual_ae-#0_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2564
test shape: (80, 32, 360, 1) (80, 32, 360, 1)
test shape: (2560, 360, 1) (2560, 360, 1)
mae:0.15608038008213043 mse:0.04576902091503143 rmse:0.2139369547367096 mape:0.35854944586753845 mspe:47.75923156738281 dtw:-999
True
Args in experiment:
[1mBasic Config[0m
  Task Name:          long_term_forecast  Is Training:        1                   
  Model ID:           20240702-221904     Model:              TimeMixer           

[1mData Loader[0m
  Data:               custom              Root Path:          /home/qc/twj/ml_data/data2/
  Data Path:          #0_hour_residual_ae.csvFeatures:           MS                  
  Target:             residual_ae         Freq:               h                   
  Checkpoints:        ./checkpoints/      

[1mForecasting Task[0m
  Seq Len:            720                 Label Len:          360                 
  Pred Len:           360                 Seasonal Patterns:  Monthly             
  Inverse:            0                   

[1mModel Parameters[0m
  Top k:              5                   Num Kernels:        6                   
  Enc In:             4                   Dec In:             4                   
  C Out:              4                   d model:            16                  
  n heads:            8                   e layers:           2                   
  d layers:           1                   d FF:               32                  
  Moving Avg:         25                  Factor:             1                   
  Distil:             1                   Dropout:            0.1                 
  Embed:              timeF               Activation:         gelu                
  Output Attention:   0                   

[1mRun Parameters[0m
  Num Workers:        10                  Itr:                1                   
  Train Epochs:       10                  Batch Size:         32                  
  Patience:           10                  Learning Rate:      0.01                
  Des:                soh-residual_ae-#0  Loss:               MSE                 
  Lradj:              type1               Use Amp:            0                   

[1mGPU[0m
  Use GPU:            1                   GPU:                0                   
  Use Multi GPU:      0                   Devices:            0,1,2,3             

[1mDe-stationary Projector Params[0m
  P Hidden Dims:      128, 128            P Hidden Layers:    2                   

Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_20240702-221904_TimeMixer_custom_ftMS_sl720_ll360_pl360_dm16_nh8_el2_dl1_df32_expand2_dc4_fc1_ebtimeF_dtTrue_soh-residual_ae-#0_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 9152
val 1104
test 2564
======================================================================
Layer (type:depth-idx)                        Param #
======================================================================
Model                                         --
â”œâ”€ModuleList: 1-1                             --
â”‚    â””â”€PastDecomposableMixing: 2-1            --
â”‚    â”‚    â””â”€LayerNorm: 3-1                    32
â”‚    â”‚    â””â”€Dropout: 3-2                      --
â”‚    â”‚    â””â”€series_decomp: 3-3                --
â”‚    â”‚    â””â”€MultiScaleSeasonMixing: 3-4       511,560
â”‚    â”‚    â””â”€MultiScaleTrendMixing: 3-5        1,023,120
â”‚    â”‚    â””â”€Sequential: 3-6                   1,072
â”‚    â””â”€PastDecomposableMixing: 2-2            --
â”‚    â”‚    â””â”€LayerNorm: 3-7                    32
â”‚    â”‚    â””â”€Dropout: 3-8                      --
â”‚    â”‚    â””â”€series_decomp: 3-9                --
â”‚    â”‚    â””â”€MultiScaleSeasonMixing: 3-10      511,560
â”‚    â”‚    â””â”€MultiScaleTrendMixing: 3-11       1,023,120
â”‚    â”‚    â””â”€Sequential: 3-12                  1,072
â”œâ”€series_decomp: 1-2                          --
â”‚    â””â”€moving_avg: 2-3                        --
â”‚    â”‚    â””â”€AvgPool1d: 3-13                   --
â”œâ”€DataEmbedding_wo_pos: 1-3                   --
â”‚    â””â”€TokenEmbedding: 2-4                    --
â”‚    â”‚    â””â”€Conv1d: 3-14                      48
â”‚    â””â”€PositionalEmbedding: 2-5               --
â”‚    â””â”€TimeFeatureEmbedding: 2-6              --
â”‚    â”‚    â””â”€Linear: 3-15                      64
â”‚    â””â”€Dropout: 2-7                           --
â”œâ”€ModuleList: 1-4                             --
â”‚    â””â”€Linear: 2-8                            259,560
â”‚    â””â”€Linear: 2-9                            129,960
â”‚    â””â”€Linear: 2-10                           65,160
â”‚    â””â”€Linear: 2-11                           32,760
â”œâ”€Linear: 1-5                                 17
â”œâ”€ModuleList: 1-6                             --
â”‚    â””â”€Normalize: 2-12                        8
â”‚    â””â”€Normalize: 2-13                        8
â”‚    â””â”€Normalize: 2-14                        8
â”‚    â””â”€Normalize: 2-15                        8
======================================================================
Total params: 3,559,169
Trainable params: 3,559,169
Non-trainable params: 0
======================================================================
	iters: 57, epoch: 1 | loss: 32627.8222656
	speed: 0.0441s/iter; left time: 123.7405s
	iters: 114, epoch: 1 | loss: 8.0491896
	speed: 0.0164s/iter; left time: 45.1866s
	iters: 171, epoch: 1 | loss: 1.6656454
	speed: 0.0163s/iter; left time: 43.9224s
	iters: 228, epoch: 1 | loss: 3.4064705
	speed: 0.0165s/iter; left time: 43.4745s
	iters: 285, epoch: 1 | loss: 1.2074585
	speed: 0.0164s/iter; left time: 42.2391s
Epoch: 1 cost time: 6.303774833679199
Epoch: 1, Steps: 286 | Train Loss: 3496.1235393 Vali Loss: 0.3372753 Test Loss: 1.2702636
Validation loss decreased (inf --> 0.337275).  Saving model ...
Updating learning rate to 0.01
	iters: 57, epoch: 2 | loss: 1.0657625
	speed: 0.0467s/iter; left time: 117.6391s
	iters: 114, epoch: 2 | loss: 1.3435556
	speed: 0.0165s/iter; left time: 40.5986s
	iters: 171, epoch: 2 | loss: 1.2489592
	speed: 0.0167s/iter; left time: 40.0440s
	iters: 228, epoch: 2 | loss: 0.7369916
	speed: 0.0166s/iter; left time: 38.9345s
	iters: 285, epoch: 2 | loss: 1.4413198
	speed: 0.0166s/iter; left time: 38.0027s
Epoch: 2 cost time: 5.0490882396698
Epoch: 2, Steps: 286 | Train Loss: 1.2938349 Vali Loss: 0.1406728 Test Loss: 0.5995542
Validation loss decreased (0.337275 --> 0.140673).  Saving model ...
Updating learning rate to 0.005
	iters: 57, epoch: 3 | loss: 1.2712101
	speed: 0.0477s/iter; left time: 106.4931s
	iters: 114, epoch: 3 | loss: 0.9307772
	speed: 0.0167s/iter; left time: 36.3350s
	iters: 171, epoch: 3 | loss: 1.1190381
	speed: 0.0169s/iter; left time: 35.7355s
	iters: 228, epoch: 3 | loss: 0.8638696
	speed: 0.0167s/iter; left time: 34.4685s
	iters: 285, epoch: 3 | loss: 0.8241054
	speed: 0.0166s/iter; left time: 33.2756s
Epoch: 3 cost time: 5.060208559036255
Epoch: 3, Steps: 286 | Train Loss: 0.7952432 Vali Loss: 0.1116570 Test Loss: 0.4411327
Validation loss decreased (0.140673 --> 0.111657).  Saving model ...
Updating learning rate to 0.0025
	iters: 57, epoch: 4 | loss: 0.7223003
	speed: 0.0465s/iter; left time: 90.5339s
	iters: 114, epoch: 4 | loss: 0.5247415
	speed: 0.0166s/iter; left time: 31.3002s
	iters: 171, epoch: 4 | loss: 0.4213594
	speed: 0.0165s/iter; left time: 30.1441s
	iters: 228, epoch: 4 | loss: 0.9265113
	speed: 0.0164s/iter; left time: 29.1680s
	iters: 285, epoch: 4 | loss: 1.1678032
	speed: 0.0164s/iter; left time: 28.1977s
Epoch: 4 cost time: 5.021012783050537
Epoch: 4, Steps: 286 | Train Loss: 0.6736322 Vali Loss: 0.0961678 Test Loss: 0.3887618
Validation loss decreased (0.111657 --> 0.096168).  Saving model ...
Updating learning rate to 0.00125
	iters: 57, epoch: 5 | loss: 1.0247439
	speed: 0.0466s/iter; left time: 77.3614s
	iters: 114, epoch: 5 | loss: 0.2843049
	speed: 0.0165s/iter; left time: 26.4889s
	iters: 171, epoch: 5 | loss: 0.4173368
	speed: 0.0166s/iter; left time: 25.6939s
	iters: 228, epoch: 5 | loss: 0.5708790
	speed: 0.0166s/iter; left time: 24.7313s
	iters: 285, epoch: 5 | loss: 0.3955518
	speed: 0.0166s/iter; left time: 23.7466s
Epoch: 5 cost time: 5.0450639724731445
Epoch: 5, Steps: 286 | Train Loss: 0.6291189 Vali Loss: 0.0964937 Test Loss: 0.4134521
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 57, epoch: 6 | loss: 0.4667875
	speed: 0.0458s/iter; left time: 62.9375s
	iters: 114, epoch: 6 | loss: 0.6472933
	speed: 0.0166s/iter; left time: 21.8776s
	iters: 171, epoch: 6 | loss: 0.4625516
	speed: 0.0166s/iter; left time: 20.9138s
	iters: 228, epoch: 6 | loss: 0.4554922
	speed: 0.0166s/iter; left time: 19.9955s
	iters: 285, epoch: 6 | loss: 0.6673011
	speed: 0.0166s/iter; left time: 18.9690s
Epoch: 6 cost time: 5.0424745082855225
Epoch: 6, Steps: 286 | Train Loss: 0.5942687 Vali Loss: 0.1071511 Test Loss: 0.4189361
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 57, epoch: 7 | loss: 0.7771921
	speed: 0.0459s/iter; left time: 49.9748s
	iters: 114, epoch: 7 | loss: 0.7387753
	speed: 0.0168s/iter; left time: 17.2799s
	iters: 171, epoch: 7 | loss: 0.6541862
	speed: 0.0165s/iter; left time: 16.0508s
	iters: 228, epoch: 7 | loss: 0.6058856
	speed: 0.0164s/iter; left time: 15.0671s
	iters: 285, epoch: 7 | loss: 0.5882373
	speed: 0.0164s/iter; left time: 14.1103s
Epoch: 7 cost time: 5.023441314697266
Epoch: 7, Steps: 286 | Train Loss: 0.6015639 Vali Loss: 0.0887528 Test Loss: 0.3692983
Validation loss decreased (0.096168 --> 0.088753).  Saving model ...
Updating learning rate to 0.00015625
	iters: 57, epoch: 8 | loss: 0.5964074
	speed: 0.0467s/iter; left time: 37.4661s
	iters: 114, epoch: 8 | loss: 0.6369550
	speed: 0.0170s/iter; left time: 12.6448s
	iters: 171, epoch: 8 | loss: 0.6032831
	speed: 0.0170s/iter; left time: 11.6664s
	iters: 228, epoch: 8 | loss: 0.5493490
	speed: 0.0167s/iter; left time: 10.5314s
	iters: 285, epoch: 8 | loss: 0.5676014
	speed: 0.0166s/iter; left time: 9.5015s
Epoch: 8 cost time: 5.096874475479126
Epoch: 8, Steps: 286 | Train Loss: 0.5767158 Vali Loss: 0.0885260 Test Loss: 0.3570887
Validation loss decreased (0.088753 --> 0.088526).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 57, epoch: 9 | loss: 0.6425402
	speed: 0.0463s/iter; left time: 23.9039s
	iters: 114, epoch: 9 | loss: 0.4258258
	speed: 0.0168s/iter; left time: 7.7065s
	iters: 171, epoch: 9 | loss: 0.5787100
	speed: 0.0169s/iter; left time: 6.7771s
	iters: 228, epoch: 9 | loss: 0.5965474
	speed: 0.0168s/iter; left time: 5.7835s
	iters: 285, epoch: 9 | loss: 0.6504574
	speed: 0.0166s/iter; left time: 4.7684s
Epoch: 9 cost time: 5.0848708152771
Epoch: 9, Steps: 286 | Train Loss: 0.5602795 Vali Loss: 0.0822770 Test Loss: 0.3675068
Validation loss decreased (0.088526 --> 0.082277).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 57, epoch: 10 | loss: 0.6577667
	speed: 0.0476s/iter; left time: 10.9383s
	iters: 114, epoch: 10 | loss: 0.5069139
	speed: 0.0168s/iter; left time: 2.9041s
	iters: 171, epoch: 10 | loss: 0.4181363
	speed: 0.0168s/iter; left time: 1.9506s
	iters: 228, epoch: 10 | loss: 0.5990979
	speed: 0.0165s/iter; left time: 0.9723s
	iters: 285, epoch: 10 | loss: 0.6994671
	speed: 0.0165s/iter; left time: 0.0329s
Epoch: 10 cost time: 5.071764707565308
Epoch: 10, Steps: 286 | Train Loss: 0.5599071 Vali Loss: 0.0843739 Test Loss: 0.3615680
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
>>>>>>>testing : long_term_forecast_20240702-221904_TimeMixer_custom_ftMS_sl720_ll360_pl360_dm16_nh8_el2_dl1_df32_expand2_dc4_fc1_ebtimeF_dtTrue_soh-residual_ae-#0_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2564
test shape: (80, 32, 360, 1) (80, 32, 360, 1)
test shape: (2560, 360, 1) (2560, 360, 1)
mae:0.40668901801109314 mse:0.36750665307044983 rmse:0.6062232851982117 mape:0.6077653765678406 mspe:99.69058227539062 dtw:-999
